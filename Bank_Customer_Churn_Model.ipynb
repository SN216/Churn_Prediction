{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053ee869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc319f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0efae43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            int64\n",
       "CustomerId           int64\n",
       "Surname             object\n",
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b06155ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('CustomerId',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aaefc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Surname',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c69a8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('RowNumber',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7193f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>526</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>190298.89</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>191263.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28726.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8282</th>\n",
       "      <td>747</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>81025.60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>167682.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>731</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22299.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>601</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>98202.76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137763.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>708</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>176702.36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>104804.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>613</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>105627.95</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36560.51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9317</th>\n",
       "      <td>741</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>106036.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>194686.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6500</th>\n",
       "      <td>582</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>153313.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170563.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>735</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>123845.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170454.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "2171          526   Germany    Male   58       9  190298.89              2   \n",
       "2488          645     Spain  Female   21       1       0.00              2   \n",
       "8282          747    France  Female   21       4   81025.60              2   \n",
       "1649          731     Spain    Male   41       4       0.00              2   \n",
       "6025          601    France  Female   46       3   98202.76              1   \n",
       "7581          708   Germany    Male   42       9  176702.36              2   \n",
       "4439          613    France  Female   21       7  105627.95              1   \n",
       "9317          741    France    Male   42       6  106036.52              1   \n",
       "6500          582    France  Female   43       5  153313.67              1   \n",
       "5866          735    France  Female   53       8  123845.36              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "2171          1               1        191263.76       0  \n",
       "2488          0               0         28726.07       0  \n",
       "8282          1               0        167682.57       0  \n",
       "1649          1               0         22299.27       0  \n",
       "6025          0               0        137763.93       0  \n",
       "7581          1               1        104804.74       0  \n",
       "4439          1               1         36560.51       0  \n",
       "9317          1               0        194686.78       1  \n",
       "6500          0               0        170563.73       0  \n",
       "5866          0               1        170454.93       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28afbb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079a3b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited', 'Geography_France',\n",
       "       'Geography_Germany', 'Geography_Spain', 'Gender_Female', 'Gender_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.get_dummies(data=df, columns=['Geography','Gender'])\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3c87952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9387e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling of required columns\n",
    "cols_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df1[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b1f52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>0.704</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>0.572</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.496009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>0.624</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.416539</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>0.748</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>0.346</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.410395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.643514</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8208</th>\n",
       "      <td>0.722</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.518862</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.159014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9484</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.464001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8206</th>\n",
       "      <td>0.460</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800495</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.208994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.805278</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.395191</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.242341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "2406        0.704  0.189189     0.8  0.285645       0.000000          1   \n",
       "5666        0.572  0.567568     0.7  0.496009       0.000000          1   \n",
       "5102        0.624  0.027027     0.9  0.416539       0.333333          0   \n",
       "2585        0.748  0.135135     0.9  0.000000       0.333333          1   \n",
       "898         0.346  0.297297     0.2  0.410395       0.000000          1   \n",
       "8208        0.722  0.148649     0.3  0.518862       0.333333          1   \n",
       "9484        0.926  0.162162     0.1  0.464001       0.000000          0   \n",
       "8206        0.460  0.216216     0.6  0.000000       0.333333          1   \n",
       "269         0.882  0.229730     0.7  0.208994       0.000000          1   \n",
       "5983        0.538  0.135135     0.6  0.395191       0.333333          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "2406               1         0.630413       0                 0   \n",
       "5666               1         0.706833       1                 0   \n",
       "5102               0         0.365515       0                 0   \n",
       "2585               1         0.501191       0                 1   \n",
       "898                0         0.643514       1                 1   \n",
       "8208               0         0.159014       0                 1   \n",
       "9484               1         0.429024       0                 0   \n",
       "8206               1         0.800495       0                 1   \n",
       "269                0         0.805278       0                 0   \n",
       "5983               0         0.242341       0                 0   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "2406                  0                1              0            1  \n",
       "5666                  0                1              0            1  \n",
       "5102                  0                1              0            1  \n",
       "2585                  0                0              0            1  \n",
       "898                   0                0              1            0  \n",
       "8208                  0                0              1            0  \n",
       "9484                  1                0              0            1  \n",
       "8206                  0                0              0            1  \n",
       "269                   1                0              1            0  \n",
       "5983                  1                0              1            0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0932fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting training and testing sets\n",
    "x = df1.drop('Exited',axis='columns')\n",
    "y = df1['Exited']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9192b615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b2a6aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db6183f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2657e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.5601 - accuracy: 0.7960\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4835 - accuracy: 0.7960\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4709 - accuracy: 0.7960\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4638 - accuracy: 0.7960\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4579 - accuracy: 0.7960\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4515 - accuracy: 0.7960\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4464 - accuracy: 0.7960\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4412 - accuracy: 0.7960\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4374 - accuracy: 0.7960\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4338 - accuracy: 0.7985\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4308 - accuracy: 0.8054\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4280 - accuracy: 0.8080\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4262 - accuracy: 0.8089\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4244 - accuracy: 0.8096\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4220 - accuracy: 0.8092\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4193 - accuracy: 0.8109\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4164 - accuracy: 0.8141\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4117 - accuracy: 0.8163\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4076 - accuracy: 0.8194\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4030 - accuracy: 0.8207\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3988 - accuracy: 0.8255\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3940 - accuracy: 0.8289\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.8326\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3861 - accuracy: 0.8366\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3819 - accuracy: 0.8374\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3782 - accuracy: 0.8394\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3753 - accuracy: 0.8432\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3716 - accuracy: 0.8465\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.3698 - accuracy: 0.8490\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3669 - accuracy: 0.8499\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3644 - accuracy: 0.8518\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3627 - accuracy: 0.8519\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3612 - accuracy: 0.8545\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3595 - accuracy: 0.8526\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8534\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3565 - accuracy: 0.8556\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3561 - accuracy: 0.8528\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3547 - accuracy: 0.8551\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8553\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3528 - accuracy: 0.8565\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3524 - accuracy: 0.8571\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3517 - accuracy: 0.8571\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3504 - accuracy: 0.8576\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3511 - accuracy: 0.8555\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3500 - accuracy: 0.8569\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3490 - accuracy: 0.8569\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3485 - accuracy: 0.8591\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3483 - accuracy: 0.8577\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3477 - accuracy: 0.8590\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8586\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3473 - accuracy: 0.8595\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8586\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3464 - accuracy: 0.8584\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3462 - accuracy: 0.8597\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3458 - accuracy: 0.8583\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8610\n",
      "Epoch 57/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3452 - accuracy: 0.8594\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8597\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8579\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8584\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.8584\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3442 - accuracy: 0.8602\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3431 - accuracy: 0.8612\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8601\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3431 - accuracy: 0.8600\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3431 - accuracy: 0.8587\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3426 - accuracy: 0.8599\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8609\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8596\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3420 - accuracy: 0.8599\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8599\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3415 - accuracy: 0.8609\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3426 - accuracy: 0.8594\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3412 - accuracy: 0.8608\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8619\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8612\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3417 - accuracy: 0.8612\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3414 - accuracy: 0.8614\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8614\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3406 - accuracy: 0.8604\n",
      "Epoch 81/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3407 - accuracy: 0.8618\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3395 - accuracy: 0.8616\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3403 - accuracy: 0.8610\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8600\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3399 - accuracy: 0.8608\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8622\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3404 - accuracy: 0.8618\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8596\n",
      "Epoch 89/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3391 - accuracy: 0.8610\n",
      "Epoch 90/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8616\n",
      "Epoch 91/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8618\n",
      "Epoch 92/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8596\n",
      "Epoch 93/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.8605\n",
      "Epoch 94/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.8637\n",
      "Epoch 95/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8611\n",
      "Epoch 96/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.8614\n",
      "Epoch 97/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8609\n",
      "Epoch 98/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8620\n",
      "Epoch 99/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3387 - accuracy: 0.8635\n",
      "Epoch 100/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3389 - accuracy: 0.8618\n",
      "Epoch 101/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3376 - accuracy: 0.8619\n",
      "Epoch 102/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8624\n",
      "Epoch 103/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8610\n",
      "Epoch 104/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8633\n",
      "Epoch 105/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8630\n",
      "Epoch 106/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.8621\n",
      "Epoch 107/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8633\n",
      "Epoch 108/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8637\n",
      "Epoch 109/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8639\n",
      "Epoch 110/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3378 - accuracy: 0.8621\n",
      "Epoch 111/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8630\n",
      "Epoch 112/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8634\n",
      "Epoch 113/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8624\n",
      "Epoch 114/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8630\n",
      "Epoch 115/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8618\n",
      "Epoch 116/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8615\n",
      "Epoch 117/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3367 - accuracy: 0.8629\n",
      "Epoch 118/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8614\n",
      "Epoch 119/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8627\n",
      "Epoch 120/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8611\n",
      "Epoch 121/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8634\n",
      "Epoch 122/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3365 - accuracy: 0.8618\n",
      "Epoch 123/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3366 - accuracy: 0.8641\n",
      "Epoch 124/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8641\n",
      "Epoch 125/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8625\n",
      "Epoch 126/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.8627\n",
      "Epoch 127/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8616\n",
      "Epoch 128/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8619\n",
      "Epoch 129/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8602\n",
      "Epoch 130/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3360 - accuracy: 0.8635\n",
      "Epoch 131/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.8630\n",
      "Epoch 132/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8651\n",
      "Epoch 133/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8635\n",
      "Epoch 134/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8618\n",
      "Epoch 135/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8608\n",
      "Epoch 136/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8636\n",
      "Epoch 137/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3346 - accuracy: 0.8614\n",
      "Epoch 138/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.8637\n",
      "Epoch 139/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3350 - accuracy: 0.8645\n",
      "Epoch 140/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8620\n",
      "Epoch 141/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3356 - accuracy: 0.8620\n",
      "Epoch 142/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8634\n",
      "Epoch 143/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8637\n",
      "Epoch 144/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.8625\n",
      "Epoch 145/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3346 - accuracy: 0.8634\n",
      "Epoch 146/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3350 - accuracy: 0.8637\n",
      "Epoch 147/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3346 - accuracy: 0.8629\n",
      "Epoch 148/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8625\n",
      "Epoch 149/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8616\n",
      "Epoch 150/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8625\n",
      "Epoch 151/500\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.3345 - accuracy: 0.8622\n",
      "Epoch 152/500\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.3346 - accuracy: 0.8615\n",
      "Epoch 153/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3345 - accuracy: 0.8631\n",
      "Epoch 154/500\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.3346 - accuracy: 0.8631\n",
      "Epoch 155/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3345 - accuracy: 0.8630\n",
      "Epoch 156/500\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 0.3349 - accuracy: 0.8645\n",
      "Epoch 157/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3344 - accuracy: 0.8637\n",
      "Epoch 158/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3351 - accuracy: 0.8633\n",
      "Epoch 159/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.8630\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3337 - accuracy: 0.8636\n",
      "Epoch 161/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.8635\n",
      "Epoch 162/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3345 - accuracy: 0.8633\n",
      "Epoch 163/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3344 - accuracy: 0.8630\n",
      "Epoch 164/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3341 - accuracy: 0.8621\n",
      "Epoch 165/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3356 - accuracy: 0.8600\n",
      "Epoch 166/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3339 - accuracy: 0.8625\n",
      "Epoch 167/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3336 - accuracy: 0.8625\n",
      "Epoch 168/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8633\n",
      "Epoch 169/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8637\n",
      "Epoch 170/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8627\n",
      "Epoch 171/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3342 - accuracy: 0.8633\n",
      "Epoch 172/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3346 - accuracy: 0.8627\n",
      "Epoch 173/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8629\n",
      "Epoch 174/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8633\n",
      "Epoch 175/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8634\n",
      "Epoch 176/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3341 - accuracy: 0.8635\n",
      "Epoch 177/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8620\n",
      "Epoch 178/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8639\n",
      "Epoch 179/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3343 - accuracy: 0.8649\n",
      "Epoch 180/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3336 - accuracy: 0.8636\n",
      "Epoch 181/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8633\n",
      "Epoch 182/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8640\n",
      "Epoch 183/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3335 - accuracy: 0.8635\n",
      "Epoch 184/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3335 - accuracy: 0.8637\n",
      "Epoch 185/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8649\n",
      "Epoch 186/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3339 - accuracy: 0.8661\n",
      "Epoch 187/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8649\n",
      "Epoch 188/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8649\n",
      "Epoch 189/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.8651\n",
      "Epoch 190/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8644\n",
      "Epoch 191/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8649\n",
      "Epoch 192/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8656\n",
      "Epoch 193/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.8660\n",
      "Epoch 194/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.8630\n",
      "Epoch 195/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3324 - accuracy: 0.8644\n",
      "Epoch 196/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8652\n",
      "Epoch 197/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.8652\n",
      "Epoch 198/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.8655\n",
      "Epoch 199/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.8648\n",
      "Epoch 200/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3320 - accuracy: 0.8640\n",
      "Epoch 201/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3322 - accuracy: 0.8646\n",
      "Epoch 202/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3321 - accuracy: 0.8651\n",
      "Epoch 203/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.8646\n",
      "Epoch 204/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8633\n",
      "Epoch 205/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8665\n",
      "Epoch 206/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8639\n",
      "Epoch 207/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.8668\n",
      "Epoch 208/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8655\n",
      "Epoch 209/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3326 - accuracy: 0.8640\n",
      "Epoch 210/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.8655\n",
      "Epoch 211/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.8637\n",
      "Epoch 212/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8643\n",
      "Epoch 213/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.8655\n",
      "Epoch 214/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8662\n",
      "Epoch 215/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8654\n",
      "Epoch 216/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8654\n",
      "Epoch 217/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8644\n",
      "Epoch 218/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8662\n",
      "Epoch 219/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3317 - accuracy: 0.8643\n",
      "Epoch 220/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3305 - accuracy: 0.8658\n",
      "Epoch 221/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8652\n",
      "Epoch 222/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8639\n",
      "Epoch 223/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.8645\n",
      "Epoch 224/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.8650\n",
      "Epoch 225/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8643\n",
      "Epoch 226/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8641\n",
      "Epoch 227/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8645\n",
      "Epoch 228/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.8646\n",
      "Epoch 229/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8654\n",
      "Epoch 230/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.8646\n",
      "Epoch 231/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8662\n",
      "Epoch 232/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8636\n",
      "Epoch 233/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8654\n",
      "Epoch 234/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8658\n",
      "Epoch 235/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8654\n",
      "Epoch 236/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8651\n",
      "Epoch 237/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8643\n",
      "Epoch 238/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8645\n",
      "Epoch 239/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8656\n",
      "Epoch 240/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8660\n",
      "Epoch 241/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3293 - accuracy: 0.8662\n",
      "Epoch 242/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8651\n",
      "Epoch 243/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8649\n",
      "Epoch 244/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8659\n",
      "Epoch 245/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3301 - accuracy: 0.8652\n",
      "Epoch 246/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3297 - accuracy: 0.8655\n",
      "Epoch 247/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8658\n",
      "Epoch 248/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8648\n",
      "Epoch 249/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8644\n",
      "Epoch 250/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8660\n",
      "Epoch 251/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8652\n",
      "Epoch 252/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8646\n",
      "Epoch 253/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8644\n",
      "Epoch 254/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8660\n",
      "Epoch 255/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3290 - accuracy: 0.8650\n",
      "Epoch 256/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8643\n",
      "Epoch 257/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8656\n",
      "Epoch 258/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8655\n",
      "Epoch 259/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8665\n",
      "Epoch 260/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8659\n",
      "Epoch 261/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8646\n",
      "Epoch 262/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3294 - accuracy: 0.8648\n",
      "Epoch 263/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8658\n",
      "Epoch 264/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8660\n",
      "Epoch 265/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3284 - accuracy: 0.8673\n",
      "Epoch 266/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8659\n",
      "Epoch 267/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8661\n",
      "Epoch 268/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3291 - accuracy: 0.8662\n",
      "Epoch 269/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8668\n",
      "Epoch 270/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8652\n",
      "Epoch 271/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8656\n",
      "Epoch 272/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8665\n",
      "Epoch 273/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8673\n",
      "Epoch 274/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8661\n",
      "Epoch 275/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8640\n",
      "Epoch 276/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8655\n",
      "Epoch 277/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8648\n",
      "Epoch 278/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8659\n",
      "Epoch 279/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8659\n",
      "Epoch 280/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3289 - accuracy: 0.8654\n",
      "Epoch 281/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3277 - accuracy: 0.8659\n",
      "Epoch 282/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8661\n",
      "Epoch 283/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8670\n",
      "Epoch 284/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3275 - accuracy: 0.8648\n",
      "Epoch 285/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8650\n",
      "Epoch 286/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - accuracy: 0.8662\n",
      "Epoch 287/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8654\n",
      "Epoch 288/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3277 - accuracy: 0.8645\n",
      "Epoch 289/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8655\n",
      "Epoch 290/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3275 - accuracy: 0.8644\n",
      "Epoch 291/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8669\n",
      "Epoch 292/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3276 - accuracy: 0.8648\n",
      "Epoch 293/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8669\n",
      "Epoch 294/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8651\n",
      "Epoch 295/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8652\n",
      "Epoch 296/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3271 - accuracy: 0.8654\n",
      "Epoch 297/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8671\n",
      "Epoch 298/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8648\n",
      "Epoch 299/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3267 - accuracy: 0.8662\n",
      "Epoch 300/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3269 - accuracy: 0.8660\n",
      "Epoch 301/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3271 - accuracy: 0.8659\n",
      "Epoch 302/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8654\n",
      "Epoch 303/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8666\n",
      "Epoch 304/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8665\n",
      "Epoch 305/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3267 - accuracy: 0.8656\n",
      "Epoch 306/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3273 - accuracy: 0.8651\n",
      "Epoch 307/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3271 - accuracy: 0.8661\n",
      "Epoch 308/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8650\n",
      "Epoch 309/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3267 - accuracy: 0.8670\n",
      "Epoch 310/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8673\n",
      "Epoch 311/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8651\n",
      "Epoch 312/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3262 - accuracy: 0.8658\n",
      "Epoch 313/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.8685\n",
      "Epoch 314/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.8661\n",
      "Epoch 315/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8644\n",
      "Epoch 316/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3265 - accuracy: 0.8658\n",
      "Epoch 317/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3266 - accuracy: 0.8669\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3264 - accuracy: 0.8650\n",
      "Epoch 319/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3266 - accuracy: 0.8661\n",
      "Epoch 320/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3268 - accuracy: 0.8648\n",
      "Epoch 321/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3266 - accuracy: 0.8671\n",
      "Epoch 322/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3264 - accuracy: 0.8652\n",
      "Epoch 323/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3254 - accuracy: 0.8673\n",
      "Epoch 324/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8669\n",
      "Epoch 325/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3260 - accuracy: 0.8669\n",
      "Epoch 326/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3263 - accuracy: 0.8643\n",
      "Epoch 327/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3264 - accuracy: 0.8668\n",
      "Epoch 328/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3269 - accuracy: 0.8648\n",
      "Epoch 329/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.8681\n",
      "Epoch 330/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3264 - accuracy: 0.8654\n",
      "Epoch 331/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3264 - accuracy: 0.8658\n",
      "Epoch 332/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.8659\n",
      "Epoch 333/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3266 - accuracy: 0.8664\n",
      "Epoch 334/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.8658\n",
      "Epoch 335/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.8661\n",
      "Epoch 336/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3256 - accuracy: 0.8652\n",
      "Epoch 337/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3259 - accuracy: 0.8671\n",
      "Epoch 338/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3260 - accuracy: 0.8660\n",
      "Epoch 339/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.8665\n",
      "Epoch 340/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8654\n",
      "Epoch 341/500\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.3255 - accuracy: 0.8674\n",
      "Epoch 342/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.8684\n",
      "Epoch 343/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8666\n",
      "Epoch 344/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3248 - accuracy: 0.8661\n",
      "Epoch 345/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.8662\n",
      "Epoch 346/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3258 - accuracy: 0.8675\n",
      "Epoch 347/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8645\n",
      "Epoch 348/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.8661\n",
      "Epoch 349/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3258 - accuracy: 0.8680\n",
      "Epoch 350/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.8661\n",
      "Epoch 351/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8658\n",
      "Epoch 352/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3263 - accuracy: 0.8661\n",
      "Epoch 353/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3253 - accuracy: 0.8669\n",
      "Epoch 354/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3258 - accuracy: 0.8644\n",
      "Epoch 355/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8670\n",
      "Epoch 356/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.8665\n",
      "Epoch 357/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8670\n",
      "Epoch 358/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8660\n",
      "Epoch 359/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3256 - accuracy: 0.8677\n",
      "Epoch 360/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3246 - accuracy: 0.8676\n",
      "Epoch 361/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8669\n",
      "Epoch 362/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8677\n",
      "Epoch 363/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8671\n",
      "Epoch 364/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8677\n",
      "Epoch 365/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3253 - accuracy: 0.8664\n",
      "Epoch 366/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3243 - accuracy: 0.8670\n",
      "Epoch 367/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.8677\n",
      "Epoch 368/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3254 - accuracy: 0.8675\n",
      "Epoch 369/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8655\n",
      "Epoch 370/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3253 - accuracy: 0.8674\n",
      "Epoch 371/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3249 - accuracy: 0.8671\n",
      "Epoch 372/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8681\n",
      "Epoch 373/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3253 - accuracy: 0.8669\n",
      "Epoch 374/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3249 - accuracy: 0.8673\n",
      "Epoch 375/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8670\n",
      "Epoch 376/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.8662\n",
      "Epoch 377/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3248 - accuracy: 0.8658\n",
      "Epoch 378/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8666\n",
      "Epoch 379/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8679\n",
      "Epoch 380/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.8662\n",
      "Epoch 381/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8665\n",
      "Epoch 382/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8673\n",
      "Epoch 383/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8664\n",
      "Epoch 384/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3241 - accuracy: 0.8674\n",
      "Epoch 385/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3250 - accuracy: 0.8664\n",
      "Epoch 386/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8668\n",
      "Epoch 387/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3241 - accuracy: 0.8662\n",
      "Epoch 388/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8666\n",
      "Epoch 389/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8665\n",
      "Epoch 390/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3238 - accuracy: 0.8670\n",
      "Epoch 391/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3255 - accuracy: 0.8651\n",
      "Epoch 392/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8670\n",
      "Epoch 393/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3245 - accuracy: 0.8670\n",
      "Epoch 394/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3248 - accuracy: 0.8652\n",
      "Epoch 395/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8659\n",
      "Epoch 396/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3253 - accuracy: 0.8668\n",
      "Epoch 397/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8669\n",
      "Epoch 398/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8665\n",
      "Epoch 399/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8669\n",
      "Epoch 400/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8673\n",
      "Epoch 401/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.8660\n",
      "Epoch 402/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8654\n",
      "Epoch 403/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8665\n",
      "Epoch 404/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8666\n",
      "Epoch 405/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8670\n",
      "Epoch 406/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3240 - accuracy: 0.8684\n",
      "Epoch 407/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8665\n",
      "Epoch 408/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.8659\n",
      "Epoch 409/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8681\n",
      "Epoch 410/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8669\n",
      "Epoch 411/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.8674\n",
      "Epoch 412/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.8659\n",
      "Epoch 413/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8659\n",
      "Epoch 414/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8656\n",
      "Epoch 415/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3252 - accuracy: 0.8656\n",
      "Epoch 416/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8654\n",
      "Epoch 417/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3243 - accuracy: 0.8664\n",
      "Epoch 418/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8680\n",
      "Epoch 419/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8669\n",
      "Epoch 420/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8665\n",
      "Epoch 421/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.8685\n",
      "Epoch 422/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8665\n",
      "Epoch 423/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8680\n",
      "Epoch 424/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8661\n",
      "Epoch 425/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8673\n",
      "Epoch 426/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3243 - accuracy: 0.8665\n",
      "Epoch 427/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.8652\n",
      "Epoch 428/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8665\n",
      "Epoch 429/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8669\n",
      "Epoch 430/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3242 - accuracy: 0.8652\n",
      "Epoch 431/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8659\n",
      "Epoch 432/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8664\n",
      "Epoch 433/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8664\n",
      "Epoch 434/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8661\n",
      "Epoch 435/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8655\n",
      "Epoch 436/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8661\n",
      "Epoch 437/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8669\n",
      "Epoch 438/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8675\n",
      "Epoch 439/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8664\n",
      "Epoch 440/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.8661\n",
      "Epoch 441/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8662\n",
      "Epoch 442/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8679\n",
      "Epoch 443/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8675\n",
      "Epoch 444/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8669\n",
      "Epoch 445/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8665\n",
      "Epoch 446/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8671\n",
      "Epoch 447/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8675\n",
      "Epoch 448/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8679\n",
      "Epoch 449/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.8674\n",
      "Epoch 450/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8661\n",
      "Epoch 451/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.8651\n",
      "Epoch 452/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.8671\n",
      "Epoch 453/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8674\n",
      "Epoch 454/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8655\n",
      "Epoch 455/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3240 - accuracy: 0.8651\n",
      "Epoch 456/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8664\n",
      "Epoch 457/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.8671\n",
      "Epoch 458/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3241 - accuracy: 0.8674\n",
      "Epoch 459/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8664\n",
      "Epoch 460/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8661\n",
      "Epoch 461/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.8673\n",
      "Epoch 462/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8654\n",
      "Epoch 463/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8655\n",
      "Epoch 464/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8658\n",
      "Epoch 465/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8656\n",
      "Epoch 466/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8664\n",
      "Epoch 467/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3231 - accuracy: 0.8659\n",
      "Epoch 468/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3231 - accuracy: 0.8685\n",
      "Epoch 469/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8674\n",
      "Epoch 470/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8668\n",
      "Epoch 471/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8648\n",
      "Epoch 472/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8671\n",
      "Epoch 473/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8673\n",
      "Epoch 474/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3237 - accuracy: 0.8677\n",
      "Epoch 475/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8654\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8676\n",
      "Epoch 477/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.8664\n",
      "Epoch 478/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.8677\n",
      "Epoch 479/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8665\n",
      "Epoch 480/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8666\n",
      "Epoch 481/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.8685\n",
      "Epoch 482/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8666\n",
      "Epoch 483/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8641\n",
      "Epoch 484/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8662\n",
      "Epoch 485/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8674\n",
      "Epoch 486/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8690\n",
      "Epoch 487/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8674\n",
      "Epoch 488/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8671\n",
      "Epoch 489/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8660\n",
      "Epoch 490/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8685\n",
      "Epoch 491/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8665\n",
      "Epoch 492/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8671\n",
      "Epoch 493/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8662\n",
      "Epoch 494/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8665\n",
      "Epoch 495/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8660\n",
      "Epoch 496/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8656\n",
      "Epoch 497/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8658\n",
      "Epoch 498/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3231 - accuracy: 0.8662\n",
      "Epoch 499/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.8668\n",
      "Epoch 500/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3224 - accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215b22f3730>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neural network model\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(13,),activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"relu\"),\n",
    "    keras.layers.Dense(1,  activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ab9c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 2s 4ms/step - loss: 0.3260 - accuracy: 0.8659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32604166865348816, 0.8658750057220459]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad2a7dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01958179],\n",
       "       [0.02733175],\n",
       "       [0.03733116],\n",
       "       ...,\n",
       "       [0.02698267],\n",
       "       [0.01008067],\n",
       "       [0.07908714]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4d00405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "yp = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c64d67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp1 = yp.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81e1a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for element in yp1:\n",
    "    if element > 0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af38a7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ffec540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7d82da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7054    0\n",
       "442     0\n",
       "3954    0\n",
       "2288    0\n",
       "3196    0\n",
       "6178    0\n",
       "8351    0\n",
       "5658    1\n",
       "2065    0\n",
       "413     1\n",
       "8594    0\n",
       "1805    0\n",
       "3631    0\n",
       "837     0\n",
       "9322    0\n",
       "4186    0\n",
       "6568    0\n",
       "5401    0\n",
       "8467    0\n",
       "1995    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f2ca884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79493a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
